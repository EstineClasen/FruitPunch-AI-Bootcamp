{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EstineClasen/FruitPunch-AI-Bootcamp/blob/main/1_1_Intro_to_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y-HINws7t4z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common AI models\n",
        "\n",
        "In this first notebook you will practice AI with some common Machine Learning models. You're expected to already have some basic experience in playing around with Python. If you find yourself stranded on one of the assignments please put a question in the bootcamp-questions Slack channel. There are mentors there that are eager to help."
      ],
      "metadata": {
        "id": "9JixMZox71uW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classic machine learning models\n",
        "\n",
        "## Assignment 1\n",
        "From the Sklearn library choose models of at least the following types, train them on the 6 imported datasets, evaluate their accuracy or R^2 and see which model works best on which dataset. (Note that there are both regression and classification sets)\n",
        "* Tree\n",
        "* Neural Network\n",
        "* Neighbors\n",
        "* Ensemble\n",
        "* Naive Byes (classification only)\n",
        "* Linear\n"
      ],
      "metadata": {
        "id": "BQjIosCd73lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris, load_boston, load_diabetes, load_digits, load_wine, load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example of how to load a dataset\n",
        "#print(load_iris().DESCR)\n",
        "\n",
        "X = load_iris().data\n",
        "y = load_iris().target\n",
        "\n",
        "# Create a train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "boxe8FST7zpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how to load/train a model and evaluate\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, RandomForestClassifier, RandomForestRegressor, BaggingClassifier, BaggingRegressor\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, CategoricalNB\n",
        "from sklearn.linear_model import LinearRegression, LassoLars, BayesianRidge\n",
        "\n",
        "#tree = DecisionTreeClassifier()             # Load\n",
        "#fitted_tree = tree.fit(X_train, y_train)    # Train\n",
        "#y_pred = fitted_tree.predict(X_test)        # Predict on unseen data\n",
        "#regressor = DecisionTreeRegressor()             # Load\n",
        "#fitted_regressor = regressor.fit(X_train, y_train)    # Train\n",
        "#y_pred = fitted_regressor.predict(X_test)        # Predict on unseen data\n",
        "#acc_score = accuracy_score(y_test, y_pred)  # Evaluate accuracy score\n",
        "#r2_score = r2_score(y_test, y_pred)         # Evaluate R^2 score\n",
        "#print(f'On the {load_iris.__name__} dataset the {DecisionTreeRegressor.__name__} reaches an accuracy score of {acc_score} and a R^2 score of {r2_score}')\n",
        "\n",
        "classifiers = [DecisionTreeClassifier, MLPClassifier, KNeighborsClassifier, ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier, BernoulliNB, GaussianNB]\n",
        "regressors = [DecisionTreeRegressor, MLPRegressor, KNeighborsRegressor, ExtraTreesRegressor, RandomForestRegressor, BaggingRegressor, LinearRegression, LassoLars, BayesianRidge]\n",
        "\n",
        "results = {}      # define dictionary\n",
        "\n",
        "data_loaders = [load_iris, load_boston, load_diabetes, load_digits, load_wine, load_breast_cancer]    #list of datasets\n",
        "\n",
        "for loader in data_loaders:         #run through list of datasets. Look at one dataset at a time\n",
        "    loader_name = loader.__name__\n",
        "    print(loader_name)\n",
        "    results[loader_name] = {}\n",
        "    X = loader().data         #inputs\n",
        "    y = loader().target       #outputs\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    if 'Classification' in loader().DESCR:    #if this word is in this text field\n",
        "        models = classifiers                  #datasets which are classification problems\n",
        "    else:\n",
        "        models = regressors                   #datasets which are regression problems\n",
        "\n",
        "    for m in models:\n",
        "        model_name = m.__name__\n",
        "        results[loader_name][model_name] = {}\n",
        "\n",
        "        fitted = m().fit(X=X_train, y=y_train)\n",
        "\n",
        "        y_pred = fitted.predict(X_test)\n",
        "\n",
        "        if 'Classification' in loader().DESCR:\n",
        "            score = accuracy_score(y_test, y_pred)\n",
        "        else: \n",
        "            score = r2_score(y_test, y_pred)\n",
        "\n",
        "        results[loader_name][model_name]['score'] = score\n",
        "        print(f'{model_name} accuracy: ', score)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfM5F3WL_GdP",
        "outputId": "c54ccff5-9492-487b-e0f9-67597bf4944c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load_iris\n",
            "DecisionTreeClassifier accuracy:  0.98\n",
            "MLPClassifier accuracy:  1.0\n",
            "KNeighborsClassifier accuracy:  0.98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExtraTreesClassifier accuracy:  0.98\n",
            "RandomForestClassifier accuracy:  0.98\n",
            "BaggingClassifier accuracy:  0.98\n",
            "BernoulliNB accuracy:  0.3\n",
            "GaussianNB accuracy:  0.96\n",
            "load_boston\n",
            "DecisionTreeRegressor accuracy:  0.7490614034150096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor accuracy:  0.6446989994879011\n",
            "KNeighborsRegressor accuracy:  0.5748334691810936\n",
            "ExtraTreesRegressor accuracy:  0.8664458283551233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor accuracy:  0.8610123871656237\n",
            "BaggingRegressor accuracy:  0.8365230119245072\n",
            "LinearRegression accuracy:  0.7261570836552481\n",
            "LassoLars accuracy:  -0.023271489839964632\n",
            "BayesianRidge accuracy:  0.7109084094872564\n",
            "load_diabetes\n",
            "DecisionTreeRegressor accuracy:  -0.2022867298037352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor accuracy:  -3.111007129577727\n",
            "KNeighborsRegressor accuracy:  0.43975256620686554\n",
            "ExtraTreesRegressor accuracy:  0.5044000446807899\n",
            "RandomForestRegressor accuracy:  0.45928797963500223\n",
            "BaggingRegressor accuracy:  0.45417972610171975\n",
            "LinearRegression accuracy:  0.510395426135144\n",
            "LassoLars accuracy:  0.40575192955734674\n",
            "BayesianRidge accuracy:  0.5093669637985777\n",
            "load_digits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier accuracy:  0.8518518518518519\n",
            "MLPClassifier accuracy:  0.9730639730639731\n",
            "KNeighborsClassifier accuracy:  0.9932659932659933\n",
            "ExtraTreesClassifier accuracy:  0.9797979797979798\n",
            "RandomForestClassifier accuracy:  0.9797979797979798\n",
            "BaggingClassifier accuracy:  0.9259259259259259\n",
            "BernoulliNB accuracy:  0.8619528619528619\n",
            "GaussianNB accuracy:  0.8164983164983165\n",
            "load_wine\n",
            "DecisionTreeClassifier accuracy:  0.9661016949152542\n",
            "MLPClassifier accuracy:  0.23728813559322035\n",
            "KNeighborsClassifier accuracy:  0.6779661016949152\n",
            "ExtraTreesClassifier accuracy:  1.0\n",
            "RandomForestClassifier accuracy:  1.0\n",
            "BaggingClassifier accuracy:  0.9830508474576272\n",
            "BernoulliNB accuracy:  0.4067796610169492\n",
            "GaussianNB accuracy:  1.0\n",
            "load_breast_cancer\n",
            "DecisionTreeRegressor accuracy:  0.6521524608363143\n",
            "MLPRegressor accuracy:  -0.5588805913550494\n",
            "KNeighborsRegressor accuracy:  0.8497298630812877\n",
            "ExtraTreesRegressor accuracy:  0.8846699888984828\n",
            "RandomForestRegressor accuracy:  0.852090588380412\n",
            "BaggingRegressor accuracy:  0.8089157518194153\n",
            "LinearRegression accuracy:  0.6911359869475926\n",
            "LassoLars accuracy:  -0.0025520372025351623\n",
            "BayesianRidge accuracy:  0.7233301374435069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KvJlaoTxcgg",
        "outputId": "d141f63b-377e-47d8-98e4-ace0e710e39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'load_iris': {'DecisionTreeClassifier': {'score': 0.96},\n",
              "  'MLPClassifier': {'score': 1.0},\n",
              "  'KNeighborsClassifier': {'score': 0.98},\n",
              "  'ExtraTreesClassifier': {'score': 0.98},\n",
              "  'RandomForestClassifier': {'score': 0.98},\n",
              "  'BaggingClassifier': {'score': 0.98},\n",
              "  'BernoulliNB': {'score': 0.3},\n",
              "  'GaussianNB': {'score': 0.96}},\n",
              " 'load_diabetes': {'DecisionTreeRegressor': {'score': -0.16207693697183356},\n",
              "  'MLPRegressor': {'score': -3.1300785391814046},\n",
              "  'KNeighborsRegressor': {'score': 0.43975256620686554},\n",
              "  'ExtraTreesRegressor': {'score': 0.5075162118688168},\n",
              "  'RandomForestRegressor': {'score': 0.4742767760919706},\n",
              "  'BaggingRegressor': {'score': 0.38786203503905137},\n",
              "  'LinearRegression': {'score': 0.510395426135144},\n",
              "  'LassoLars': {'score': 0.40575192955734674},\n",
              "  'BayesianRidge': {'score': 0.5093669637985777}},\n",
              " 'load_digits': {'DecisionTreeClassifier': {'score': 0.8383838383838383},\n",
              "  'MLPClassifier': {'score': 0.9747474747474747},\n",
              "  'KNeighborsClassifier': {'score': 0.9932659932659933},\n",
              "  'ExtraTreesClassifier': {'score': 0.9848484848484849},\n",
              "  'RandomForestClassifier': {'score': 0.9713804713804713},\n",
              "  'BaggingClassifier': {'score': 0.9326599326599326},\n",
              "  'BernoulliNB': {'score': 0.8619528619528619},\n",
              "  'GaussianNB': {'score': 0.8164983164983165}},\n",
              " 'load_wine': {'DecisionTreeClassifier': {'score': 0.9661016949152542},\n",
              "  'MLPClassifier': {'score': 0.3389830508474576},\n",
              "  'KNeighborsClassifier': {'score': 0.6779661016949152},\n",
              "  'ExtraTreesClassifier': {'score': 1.0},\n",
              "  'RandomForestClassifier': {'score': 1.0},\n",
              "  'BaggingClassifier': {'score': 0.9491525423728814},\n",
              "  'BernoulliNB': {'score': 0.4067796610169492},\n",
              "  'GaussianNB': {'score': 1.0}},\n",
              " 'load_breast_cancer': {'DecisionTreeRegressor': {'score': 0.6289626248920686},\n",
              "  'MLPRegressor': {'score': -1.9686549706826142},\n",
              "  'KNeighborsRegressor': {'score': 0.8497298630812877},\n",
              "  'ExtraTreesRegressor': {'score': 0.8848694214876033},\n",
              "  'RandomForestRegressor': {'score': 0.8401408659183421},\n",
              "  'BaggingRegressor': {'score': 0.780856050326878},\n",
              "  'LinearRegression': {'score': 0.6911359869475926},\n",
              "  'LassoLars': {'score': -0.0025520372025351623},\n",
              "  'BayesianRidge': {'score': 0.7233301374435069}}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the best model for each dataset\n",
        "for key_res, val_res in results.items():      #key-value pairs in results dict\n",
        "    best_model = ''\n",
        "    highest_score = -999\n",
        "    for a, b, in val_res.items():\n",
        "        if b['score'] > highest_score:\n",
        "            best_model = a\n",
        "            highest_score = b['score']\n",
        "    print(f'Best model on {key_res} was {best_model} with score: {highest_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD8QjgU1tMwh",
        "outputId": "99bd8290-91ee-4ca7-9ec5-6eb524546c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model on load_iris was MLPClassifier with score: 1.0\n",
            "Best model on load_boston was ExtraTreesRegressor with score: 0.8664458283551233\n",
            "Best model on load_diabetes was LinearRegression with score: 0.510395426135144\n",
            "Best model on load_digits was KNeighborsClassifier with score: 0.9932659932659933\n",
            "Best model on load_wine was ExtraTreesClassifier with score: 1.0\n",
            "Best model on load_breast_cancer was ExtraTreesRegressor with score: 0.8846699888984828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 2\n",
        "Use XGBoost running on GPU to predict the same datasets. You can activate GPU acceleration in the Runtime tab:\n",
        "Runtime -> Change runtime type -> Select GPU from the dropdown"
      ],
      "metadata": {
        "id": "2lkpnT2YJIgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "results = {}      # define dictionary\n",
        "\n",
        "data_loaders = [load_iris, load_boston, load_diabetes, load_digits, load_wine, load_breast_cancer]    #list of datasets\n",
        "\n",
        "for loader in data_loaders:         #run through list of datasets. Look at one dataset at a time\n",
        "    loader_name = loader.__name__\n",
        "    print(loader_name)\n",
        "    results[loader_name] = {}\n",
        "    X = loader().data         #inputs\n",
        "    y = loader().target       #outputs\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    if 'Classification' in loader().DESCR:    #if this word is in this text field\n",
        "        models = XGBClassifier                  #datasets which are classification problems\n",
        "    else:\n",
        "        models = XGBRegressor                   #datasets which are regression problems\n",
        "    model_name = models.__name__\n",
        "    models = models(tree_method='gpu_hist') #Make sure you're connected to a GPU - Edit > Notebook settings > Hardware accelerator > GPU\n",
        "    results[loader_name][model_name] = {}\n",
        "\n",
        "    fitted = models.fit(X=X_train, y=y_train)\n",
        "\n",
        "    y_pred = fitted.predict(X_test)\n",
        "\n",
        "    if 'Classification' in loader().DESCR:\n",
        "       score = accuracy_score(y_test, y_pred)\n",
        "    else: \n",
        "       score = r2_score(y_test, y_pred)\n",
        "\n",
        "    results[loader_name][model_name]['score'] = score\n",
        "    print(f'{model_name} accuracy: ', score)\n",
        "\n"
      ],
      "metadata": {
        "id": "21RqHj3JJJRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ac1e38-3209-435f-8b70-fe1d7eaa92cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load_iris\n",
            "XGBClassifier accuracy:  0.98\n",
            "load_boston\n",
            "[13:28:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBRegressor accuracy:  0.8906424514798732\n",
            "load_diabetes\n",
            "[13:28:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "XGBRegressor accuracy:  0.4297231468315629\n",
            "load_digits\n",
            "XGBClassifier accuracy:  0.9646464646464646\n",
            "load_wine\n",
            "XGBClassifier accuracy:  0.9830508474576272\n",
            "load_breast_cancer\n",
            "[13:28:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "XGBRegressor accuracy:  0.8301625511124916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50AqnvUc0QRf",
        "outputId": "3269bfa1-ec6e-420f-da83-210940dd5f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'load_iris': {'XGBClassifier': {'score': 0.98}},\n",
              " 'load_boston': {'XGBRegressor': {'score': 0.8906424514798732}},\n",
              " 'load_diabetes': {'XGBRegressor': {'score': 0.4297231468315629}},\n",
              " 'load_digits': {'XGBClassifier': {'score': 0.9646464646464646}},\n",
              " 'load_wine': {'XGBClassifier': {'score': 0.9830508474576272}},\n",
              " 'load_breast_cancer': {'XGBRegressor': {'score': 0.8301625511124916}}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_OcKcB-0RoG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}